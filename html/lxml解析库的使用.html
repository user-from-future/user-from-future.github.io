<html>
 <head>
  <title>
   lxml解析库的使用
  </title>
  <link data-noprefix="" href="prism.css" rel="stylesheet">
  <style>
   a{
    color: black;
    text-decoration: none;
}
a:hover{
    color: blue;
}
ul{
    list-style: none;
}
#catalogue {
    top: 10px;
    right: 10px;
    z-index: 1;
    padding: 5px 10px;
    position: absolute;
    border: 1px solid blue;
    background-color: white;
}
  </style>
 </head>
 <body>
  <h1>
   <a>
    lxml解析库的使用
   </a>
  </h1>
  <ul id="catalogue">
   <li title="返回目录">
    <a href="/html">
     返回目录
    </a>
   </li>
   <li title="前言">
    <a href="#user-content-前言">
     前言
    </a>
   </li>
   <ul>
    <li title=" ">
     <a href="#user-content- ">
     </a>
    </li>
    <ul>
     <li title="模块使用">
      <a href="#user-content-模块使用">
       模块使用
      </a>
     </li>
     <li title="模块介绍">
      <a href="#user-content-模块介绍">
       模块介绍
      </a>
     </li>
    </ul>
    <li title="使用XPath">
     <a href="#user-content-使用xpath">
      使用XPath
     </a>
    </li>
    <ul>
     <li title="XPath概览">
      <a href="#user-content-xpath概览">
       XPath概览
      </a>
     </li>
     <li title="XPath常用规则">
      <a href="#user-content-xpath常用规则">
       XPath常用规则
      </a>
     </li>
    </ul>
   </ul>
  </ul>
  <h1>
   <a aria-hidden="true" class="anchor" href="#前言" id="user-content-前言">
    <span aria-hidden="true" class="octicon octicon-link">
    </span>
   </a>
   前言
  </h1>
  <p>
   <img alt="" src="https://img-blog.csdnimg.cn/1b83b1d3fff541e6844ba7bfc4b8f724.gif" style="max-width: 100%;">
  </p>
  <blockquote>
   <p>
    我们要实现了一个最基本的爬虫，但提取页面信息时使用的是正则表达式，这还是比较烦琐，而且万一有地方写错了，可能导致匹配失败，所以使用正则表达式提取页面信息多多少少还是有些不方便。
   </p>
  </blockquote>
  <p>
   <strong>
    目录
   </strong>
  </p>
  <p>
   <a href="#%E5%89%8D%E8%A8%80">
    前言
   </a>
  </p>
  <p>
   <a href="#%E7%8E%AF%E5%A2%83%E4%BD%BF%E7%94%A8">
    环境使用
   </a>
  </p>
  <p>
   <a href="#%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8">
    模块使用
   </a>
  </p>
  <p>
   <a href="#%E6%A8%A1%E5%9D%97%E4%BB%8B%E7%BB%8D">
    模块介绍
   </a>
  </p>
  <p>
   <a href="#%E4%BD%BF%E7%94%A8XPath">
    使用XPath
   </a>
  </p>
  <p>
   <a href="#XPath%E6%A6%82%E8%A7%88">
    XPath概览
   </a>
  </p>
  <p>
   <a href="#XPath%E5%B8%B8%E7%94%A8%E8%A7%84%E5%88%99">
    XPath常用规则
   </a>
  </p>
  <hr>
  <p>
   <strong>
    环境使用
   </strong>
  </p>
  <ul>
   <li>
    python 3.9
   </li>
   <li>
    pycharm
   </li>
  </ul>
  <h3>
   <a aria-hidden="true" class="anchor" href="#模块使用" id="user-content-模块使用">
    <span aria-hidden="true" class="octicon octicon-link">
    </span>
   </a>
   <strong>
    模块使用
   </strong>
  </h3>
  <ul>
   <li>
    requests
   </li>
  </ul>
  <h3>
   <a aria-hidden="true" class="anchor" href="#模块介绍" id="user-content-模块介绍">
    <span aria-hidden="true" class="octicon octicon-link">
    </span>
   </a>
   <strong>
    模块介绍
   </strong>
  </h3>
  <blockquote>
   <ul>
    <li>
     <strong>
      requests
     </strong>
    </li>
   </ul>
   <p>
    requests是一个很实用的Python HTTP客户端库，爬虫和测试服务器响应数据时经常会用到，requests是Python语言的第三方的库，专门用于发送HTTP请求，使用起来比urllib简洁很多。
   </p>
   <ul>
    <li>
     <strong>
      parsel
     </strong>
    </li>
   </ul>
   <p>
    parsel是一个python的第三方库，相当于css选择器+xpath+re。
   </p>
   <p>
    parsel由scrapy团队开发，是将scrapy中的parsel独立抽取出来的，可以轻松解析html，xml内容，获取需要的数据。
   </p>
   <p>
    相比于BeautifulSoup，xpath，parsel效率更高，使用更简单。
   </p>
   <ul>
    <li>
     <strong>
      re
     </strong>
    </li>
   </ul>
   <p>
    re模块是python独有的匹配字符串的模块，该模块中提供的很多功能是基于正则表达式实现的，而正则表达式是对字符串进行模糊匹配，提取自己需要的字符串部分，他对所有的语言都通用。
   </p>
   <ul>
    <li>
     <strong>
      os
     </strong>
    </li>
   </ul>
   <p>
    os 就是 &ldquo;operating system&rdquo; 的缩写，顾名思义，
    <a href="https://so.csdn.net/so/search?q=os%E6%A8%A1%E5%9D%97&amp;spm=1001.2101.3001.7020" rel="nofollow" title="os模块">
     os模块
    </a>
    提供的就是各种 Python 程序与操作系统进行交互的接口。通过使用 os 模块，一方面可以方便地与操作系统进行交互，另一方面也可以极大增强代码的可移植性。
   </p>
   <ul>
    <li>
     <strong>
      csv
     </strong>
    </li>
   </ul>
   <p>
    它是一种文件格式，一般也被叫做逗号分隔值文件，可以使用 Excel 软件或者文本文档打开 。其中数据字段用半角逗号间隔（也可以使用其它字符），使用 Excel 打开时，逗号会被转换为分隔符。csv 文件是以纯文本形式存储了表格数据，并且在兼容各个操作系统。
   </p>
  </blockquote>
  <p>
   <strong>
    模块安装问题:
   </strong>
  </p>
  <ul>
   <li>
    如果安装python第三方模块:
   </li>
  </ul>
  <blockquote>
   <p>
    win + R 输入 cmd 点击确定, 输入安装命令 pip install 模块名 (pip install requests) 回车
   </p>
   <p>
    在pycharm中点击Terminal(终端) 输入安装命令
   </p>
  </blockquote>
  <ul>
   <li>
    安装失败原因:
   </li>
  </ul>
  <blockquote>
   <ul>
    <li>
     失败一: pip 不是内部命令
    </li>
   </ul>
   <p>
    解决方法: 设置环境变量
   </p>
   <ul>
    <li>
     失败二: 出现大量报红 (read time out)
    </li>
   </ul>
   <p>
    解决方法: 因为是网络链接超时, 需要切换镜像源
   </p>
   <pre class="line-numbers"><code class="language-python">清华：https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>tuna<span class="token punctuation">.</span>tsinghua<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>simple
    阿里云：https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>aliyun<span class="token punctuation">.</span>com<span class="token operator">/</span>pypi<span class="token operator">/</span>simple<span class="token operator">/</span>
    中国科技大学 https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>mirrors<span class="token punctuation">.</span>ustc<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>simple<span class="token operator">/</span>
    华中理工大学：https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>hustunique<span class="token punctuation">.</span>com<span class="token operator">/</span>
    山东理工大学：https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>sdutlinux<span class="token punctuation">.</span>org<span class="token operator">/</span>
    豆瓣：https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>douban<span class="token punctuation">.</span>com<span class="token operator">/</span>simple<span class="token operator">/</span>
    例如：pip3 install <span class="token operator">-</span>i https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>doubanio<span class="token punctuation">.</span>com<span class="token operator">/</span>simple<span class="token operator">/</span> 模块名</code></pre>
   <p>
    失败三: cmd里面显示已经安装过了, 或者安装成功了, 但是在pycharm里面还是无法导入
   </p>
   <p>
    解决方法: 可能安装了多个python版本 (anaconda 或者 python 安装一个即可) 卸载一个就好，或者你pycharm里面python解释器没有设置好。
   </p>
  </blockquote>
  <p>
   我们要实现了一个最基本的爬虫，但提取页面信息时使用的是正则表达式，这还是比较烦琐，而且万一有地方写错了，可能导致匹配失败，所以使用正则表达式提取页面信息多多少少还是有些不方便。
  </p>
  <p>
   我们今天说说另外一种方法。
  </p>
  <p>
   对于网页的节点来说，它可以定义id、class或其他属性。而且节点之间还有层次关系，在网页中可以通过XPath或CSS选择器来定位一个或多个节点。那么，在页面解析时，利用XPath或CSS选择器来提取某个节点，然后再调用相应方法获取它的正文内容或者属性，不就可以提取我们想要的任意信息了吗?
  </p>
  <p>
   在Python中 ,怎样实现这个操作呢?不用担心,这种解析库已经非常多,其中比较强大的库有lxml ,Beautiful Soup、pyquery 等，我们将会介绍这3个解析库的用法。有了它们，我们就不用再为正则表达式发愁,而且解析效率也会大大提高。
  </p>
  <h2>
   <a aria-hidden="true" class="anchor" href="#使用xpath" id="user-content-使用xpath">
    <span aria-hidden="true" class="octicon octicon-link">
    </span>
   </a>
   使用XPath
  </h2>
  <p>
   XPath，全称XML Path Language，即 XML路径语言，它是一门在XML文档中查找信息的语言。它最初是用来搜寻XML文档的,但是它同样适用于HTML文档的搜索。
   <br>
   所以在做爬虫时，我们完全可以使用XPath来做相应的信息抽取。本节中，我们就来介绍XPath的基本用法。
  </p>
  <h3>
   <a aria-hidden="true" class="anchor" href="#xpath概览" id="user-content-xpath概览">
    <span aria-hidden="true" class="octicon octicon-link">
    </span>
   </a>
   XPath概览
  </h3>
  <p>
   XPath 的选择功能十分强大，它提供了非常简洁明了的路径选择表达式。另外，它还提供了超过100个内建函数，用于字符串、数值、时间的匹配以及节点、序列的处理等。几乎所有我们想要定位的节点，都可以用XPath来选择。
   <br>
   XPath于1999年11月16日成为W3C标准，它被设计为供XSLT、XPointer以及其他XML解析软件使用，更多的文档可以访问其官方网站:
   <a href="https://www.w3.org/TR/xpath/" rel="nofollow">
    https://www.w3.org/TR/xpath/
   </a>
   。
  </p>
  <h3>
   <a aria-hidden="true" class="anchor" href="#xpath常用规则" id="user-content-xpath常用规则">
    <span aria-hidden="true" class="octicon octicon-link">
    </span>
   </a>
   XPath常用规则
  </h3>
  <p>
   这里列出了XPath的常用匹配规则,示例如下:[/title[@lang=" eng']
   <br>
   这就是一个XPath规则，它代表选择所有名称为title，同时属性lang 的值为eng 的节点。后面会通过Python的 lxml库，利用XPath进行HTML的解析。
  </p>
  <p>
   后面就会学习到子节点，父节点，节点的相关知识，我们在使用的时候要先安装lxml模块，我们今天就说到这里。
  </p>
  <p>
   <img alt="6adf31c8c5dd4e6a83314f4805b30bc1.jpg" src="https://img-blog.csdnimg.cn/6adf31c8c5dd4e6a83314f4805b30bc1.jpg" style="max-width: 100%;">
  </p>
  <script src="prism.js">
  </script>
  <script>
   window.onscroll = function() {
    document.getElementById('catalogue').style.top = window.pageYOffset + 'px';
}
  </script>
 </body>
</html>